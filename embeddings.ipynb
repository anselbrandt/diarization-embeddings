{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speaker 1: Yeah, thank you for your submission. All right, great. Thank you.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle as pkl\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "\n",
    "output_dir = os.path.join(ROOT, \"output\")\n",
    "\n",
    "output_dirs = [\n",
    "    (os.path.join(output_dir, dir, subdir), dir, subdir)\n",
    "    for dir in os.listdir(output_dir)\n",
    "    for subdir in os.listdir(os.path.join(output_dir, dir))\n",
    "    if os.path.isdir(os.path.join(output_dir, dir))\n",
    "    if \".DS_Store\" not in subdir\n",
    "]\n",
    "\n",
    "output_files = [\n",
    "    (os.path.join(dir, file), file, showname, episode)\n",
    "    for dir, showname, episode in output_dirs\n",
    "    for file in os.listdir(dir)\n",
    "    if os.path.isfile(os.path.join(dir, file))\n",
    "    if \".txt\" in file\n",
    "    if \".DS_Store\" not in file\n",
    "]\n",
    "\n",
    "rotl = sorted(\n",
    "    [path for path, filename, showname, episode in output_files if showname == \"rotl\"]\n",
    ")\n",
    "\n",
    "roadwork = sorted(\n",
    "    [\n",
    "        path\n",
    "        for path, filename, showname, episode in output_files\n",
    "        if showname == \"roadwork\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def getMissing(list):\n",
    "    last_element = sorted(list)[-1]\n",
    "\n",
    "    for num in range(1, int(last_element) + 1):\n",
    "        padded = str(num).rjust(3, \"0\")\n",
    "        if padded not in list:\n",
    "            print(padded)\n",
    "\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "transcripts_dir = os.path.join(ROOT, \"transcripts\")\n",
    "\n",
    "\n",
    "def copyTranscripts():\n",
    "\n",
    "    roadwork_dir = os.path.join(transcripts_dir, \"roadwork\")\n",
    "    rotl_dir = os.path.join(transcripts_dir, \"rotl\")\n",
    "    os.makedirs(roadwork_dir, exist_ok=True)\n",
    "    os.makedirs(rotl_dir, exist_ok=True)\n",
    "\n",
    "    for file in output_files:\n",
    "        path, filename, showname, episode = file\n",
    "        shutil.copy(path, os.path.join(transcripts_dir, showname, filename))\n",
    "\n",
    "\n",
    "def getSentences(path):\n",
    "    transcript = (\n",
    "        open(path, encoding=\"utf-8-sig\").read().replace(\"\\n\\n\", \"\\n\").splitlines()\n",
    "    )\n",
    "    # splitSentences = [line.split(\": \")[1] for line in transcript]\n",
    "    sentences = [line for line in transcript]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "sentences = getSentences(roadwork[0])\n",
    "\n",
    "sentences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1826e-02, -7.9285e-02,  2.1631e-01, -5.4321e-02,  9.2285e-02,\n",
       "         3.1319e-03, -1.8835e-01,  4.5013e-02, -1.5332e-01,  5.6274e-02,\n",
       "        -3.7598e-02,  1.2585e-01,  7.9407e-02, -1.3321e-02, -1.1670e-01,\n",
       "         2.7649e-02, -1.7792e-02, -2.1069e-01,  1.3763e-02, -3.3936e-02,\n",
       "        -1.6998e-02, -8.0627e-02,  2.6733e-02,  1.1200e-01, -6.3293e-02,\n",
       "        -1.3599e-01,  1.3281e-01, -1.1908e-01,  5.6488e-02, -8.1787e-02,\n",
       "         1.0852e-01, -5.6976e-02,  4.8676e-02, -5.0934e-02, -1.9318e-02,\n",
       "        -2.8412e-02,  1.0175e-01,  2.4866e-01,  7.1838e-02,  1.2932e-02,\n",
       "         4.6349e-03, -8.7708e-02,  7.0251e-02, -1.3477e-01, -3.2593e-02,\n",
       "        -4.1779e-02,  8.6975e-03,  1.5076e-01,  1.0651e-01,  6.9656e-03,\n",
       "         1.6431e-01, -2.0996e-02, -4.5654e-02, -2.1667e-02,  2.2473e-01,\n",
       "        -9.9411e-03,  3.1113e-02,  7.9956e-03, -2.0615e-02,  6.4392e-02,\n",
       "        -1.3123e-01, -9.4116e-02,  7.5928e-02,  1.3220e-01,  1.7532e-02,\n",
       "         4.6883e-03, -1.7960e-02,  4.6570e-02, -1.0217e-01, -1.7065e-01,\n",
       "        -1.1188e-01, -6.3354e-02, -7.7972e-03,  5.2948e-03,  1.0107e-01,\n",
       "        -1.6212e-04, -9.4116e-02, -1.5149e-01, -6.1035e-02,  7.8491e-02,\n",
       "         7.3303e-02,  4.0558e-02,  3.8147e-02, -7.0457e-03,  1.0101e-01,\n",
       "         8.6823e-03,  1.0797e-01, -1.0233e-03, -1.3391e-01, -7.2876e-02,\n",
       "        -3.9429e-02, -7.3792e-02, -7.9102e-02, -7.3608e-02,  3.2532e-02,\n",
       "         1.5332e-01, -5.0140e-02, -3.5797e-02,  1.4600e-01,  1.2573e-01,\n",
       "         9.1675e-02,  7.1106e-02, -6.9847e-03, -6.4697e-03,  8.6548e-02,\n",
       "        -1.7426e-02,  3.7140e-02,  1.8506e-01,  1.0956e-01, -1.3733e-02,\n",
       "         5.5450e-02,  3.7140e-02, -4.2236e-02, -2.4902e-02,  5.5969e-02,\n",
       "         2.4490e-02, -2.8152e-02,  3.2715e-02,  8.7952e-02,  1.1395e-01,\n",
       "        -5.9967e-02,  8.9233e-02,  2.9205e-02,  1.3538e-01, -1.5015e-01,\n",
       "         4.2999e-02, -1.3281e-01,  2.0813e-01,  4.2572e-02,  1.1053e-01,\n",
       "        -4.1718e-02,  5.5603e-02, -6.0272e-02, -6.1493e-02,  1.2091e-01,\n",
       "         2.0844e-02,  5.2063e-02,  3.1143e-02,  9.5093e-02, -6.3049e-02,\n",
       "        -2.9678e-02, -6.2408e-02, -3.1433e-02,  1.1737e-01,  3.4943e-02,\n",
       "         3.9917e-02,  1.9760e-02,  1.4050e-01, -2.5291e-03, -3.9940e-03,\n",
       "         6.1798e-02, -4.3304e-02,  6.2195e-02, -1.1230e-01, -1.1322e-01,\n",
       "         2.3682e-02, -3.4752e-03, -9.1553e-02, -1.8799e-01, -9.4727e-02,\n",
       "        -5.0446e-02,  5.0720e-02,  2.8046e-02, -4.0527e-02, -1.1176e-01,\n",
       "         6.5063e-02,  2.1820e-02,  4.9225e-02, -6.4926e-03,  3.4943e-02,\n",
       "        -8.5754e-02,  5.4413e-02,  2.5009e-02,  7.6172e-02, -6.4514e-02,\n",
       "        -1.8005e-02,  1.4209e-01,  1.9135e-02, -7.5562e-02, -2.0935e-02,\n",
       "         4.1016e-02,  6.5002e-02,  1.5466e-01,  1.1665e-02,  5.8105e-02,\n",
       "        -4.7882e-02,  2.6413e-02,  6.9519e-02, -4.4067e-02,  1.2146e-01,\n",
       "        -1.8066e-02,  5.9082e-02])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_dir = os.path.join(ROOT, \"sample\", \"speaker_outputs\")\n",
    "embeddings_dir = os.path.join(segments_dir, \"embeddings\")\n",
    "\n",
    "embeddings_files = [\n",
    "    os.path.join(embeddings_dir, file)\n",
    "    for file in os.listdir(embeddings_dir)\n",
    "    if os.path.isfile(os.path.join(embeddings_dir, file))\n",
    "]\n",
    "\n",
    "sizes = [\n",
    "    pkl.load(\n",
    "        open(\n",
    "            file,\n",
    "            \"rb\",\n",
    "        )\n",
    "    )[\n",
    "        \"mono_file\"\n",
    "    ].size()[0]\n",
    "    for file in embeddings_files\n",
    "]\n",
    "\n",
    "\n",
    "nested_embeddings = [\n",
    "    pkl.load(\n",
    "        open(\n",
    "            file,\n",
    "            \"rb\",\n",
    "        )\n",
    "    )[\"mono_file\"]\n",
    "    for file in embeddings_files\n",
    "]\n",
    "\n",
    "embeddings = [tensor for tensors in nested_embeddings for tensor in tensors]\n",
    "\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_filepath': '/home/ansel/dev/diarization-pipeline/temp_outputs/mono_file.wav',\n",
       " 'offset': 6.54,\n",
       " 'duration': 0.13999999999999968,\n",
       " 'label': 'UNK',\n",
       " 'uniq_id': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "segments_dir = os.path.join(ROOT, \"sample\", \"speaker_outputs\")\n",
    "\n",
    "segments_files = [\n",
    "    os.path.join(segments_dir, file)\n",
    "    for file in os.listdir(segments_dir)\n",
    "    if \".json\" in file\n",
    "    if os.path.isfile(os.path.join(segments_dir, file))\n",
    "]\n",
    "\n",
    "segments = [\n",
    "    json.loads(line)\n",
    "    for file in segments_files\n",
    "    for line in open(file).read().splitlines()\n",
    "]\n",
    "\n",
    "segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.539999961853027, 6.679999828338623, 'speaker_1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_file = os.path.join(segments_dir, \"subsegments_scale4_cluster.label\")\n",
    "\n",
    "labels = [\n",
    "    (float(line.split(\" \")[1]), float(line.split(\" \")[2]), line.split(\" \")[3])\n",
    "    for line in open(labels_file).read().splitlines()\n",
    "]\n",
    "\n",
    "labels[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
